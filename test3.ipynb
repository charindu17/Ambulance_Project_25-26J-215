{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2953c0c9",
   "metadata": {},
   "source": [
    "# Test 3 — Improved Training Notebook\n",
    "This notebook provides a robust, reproducible training pipeline for the drowsiness detection dataset.\n",
    "It uses tf.data, MobileNetV2 transfer learning, class weighting, callbacks, and a short fine-tuning stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bd96720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.utils import class_weight\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f02ad2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR: /Users/charinduliyanage17/Documents/GitHub/Research_Test/Dataset\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "BASE_DIR = r\"/Users/charinduliyanage17/Documents/GitHub/Research_Test/Dataset\"\n",
    "TRAIN_DIR = os.path.join(BASE_DIR, 'Train')\n",
    "VAL_DIR = os.path.join(BASE_DIR, 'Val')\n",
    "# If you have a separate test folder, set TEST_DIR otherwise set to None\n",
    "TEST_DIR = os.path.join(BASE_DIR, 'Test') if os.path.exists(os.path.join(BASE_DIR, 'Test')) else None\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "SEED = 123\n",
    "print('BASE_DIR:', BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f225088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Found 8548 files belonging to 4 classes.\n",
      "Found 1554 files belonging to 4 classes.\n",
      "Found 1464 files belonging to 4 classes.\n",
      "Found classes (order): ['Closed_Eyes', 'No_yawn', 'Open_Eyes', 'Yawn']\n",
      "Num classes: 4\n"
     ]
    }
   ],
   "source": [
    "# Load datasets using tf.data utilities (returns batched datasets)\n",
    "print('Loading datasets...')\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    label_mode='categorical',\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=SEED\n",
    ")\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    VAL_DIR,\n",
    "    label_mode='categorical',\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=SEED\n",
    ")\n",
    "test_ds = None\n",
    "if TEST_DIR:\n",
    "    test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        TEST_DIR,\n",
    "        label_mode='categorical',\n",
    "        image_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        seed=SEED\n",
    "    )\n",
    "class_names = train_ds.class_names\n",
    "NUM_CLASSES = len(class_names)\n",
    "print('Found classes (order):', class_names)\n",
    "print('Num classes:', NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ae1402b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets prepared.\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing & augmentation pipeline (fast, on-the-fly)\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(0.08),\n",
    "    layers.RandomZoom(0.08),\n",
    "    layers.RandomContrast(0.08),\n",
    "])\n",
    "\n",
    "def preprocess(images, labels):\n",
    "    # images are uint8 in [0,255] - convert to float32 and apply model preprocess\n",
    "    images = tf.cast(images, tf.float32)\n",
    "    images = preprocess_input(images)  # mobilenet_v2 preprocessing -> scales to [-1,1]\n",
    "    return images, labels\n",
    "\n",
    "def augment(images, labels):\n",
    "    images = data_augmentation(images)\n",
    "    return images, labels\n",
    "\n",
    "# Apply augmentation only to training dataset and optimize pipelines\n",
    "train_ds = train_ds.map(preprocess, num_parallel_calls=AUTOTUNE)\n",
    "train_ds = train_ds.map(augment, num_parallel_calls=AUTOTUNE)\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(AUTOTUNE)\n",
    "\n",
    "val_ds = val_ds.map(preprocess, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(AUTOTUNE)\n",
    "\n",
    "if test_ds is not None:\n",
    "    test_ds = test_ds.map(preprocess, num_parallel_calls=AUTOTUNE).cache().prefetch(AUTOTUNE)\n",
    "\n",
    "print('Datasets prepared.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d0d1496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8548 files belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 23:26:01.766224: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-11-16 23:26:01.792833: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed class weights: {0: 1.0532281912272055, 1: 0.9870669745958429, 2: 0.9696007259528131, 3: 0.9939534883720931}\n"
     ]
    }
   ],
   "source": [
    "# Compute class weights to handle imbalance (if any)\n",
    "# Extract labels from the (unbatched) train dataset to compute weights\n",
    "y_train = []\n",
    "for images, labels in tf.data.Dataset.from_generator(lambda: train_ds.unbatch(), output_signature=(tf.TensorSpec(shape=(None,None,3), dtype=tf.float32), tf.TensorSpec(shape=(NUM_CLASSES,), dtype=tf.float32))):\n",
    "    pass\n",
    "# The above attempt to re-use the generator can be unreliable; instead collect labels by iterating over the original image_dataset_from_directory output\n",
    "y_labels = []\n",
    "for batch_images, batch_labels in tf.keras.utils.image_dataset_from_directory(TRAIN_DIR, label_mode='categorical', image_size=IMG_SIZE, batch_size=BATCH_SIZE, seed=SEED):\n",
    "    y_labels.extend(np.argmax(batch_labels.numpy(), axis=1).tolist())\n",
    "\n",
    "class_weights = dict()\n",
    "if len(y_labels) > 0:\n",
    "    classes = np.unique(y_labels)\n",
    "    weights = class_weight.compute_class_weight('balanced', classes=classes, y=y_labels)\n",
    "    class_weights = {int(c): float(w) for c, w in zip(classes, weights)}\n",
    "\n",
    "print('Computed class weights:', class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d9d04bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ true_divide (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TrueDivide</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ subtract (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Subtract</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mobilenetv2_1.00_224            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">327,936</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,028</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ true_divide (\u001b[38;5;33mTrueDivide\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ subtract (\u001b[38;5;33mSubtract\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m327,936\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │         \u001b[38;5;34m1,028\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,587,972</span> (9.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,587,972\u001b[0m (9.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">329,476</span> (1.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m329,476\u001b[0m (1.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,258,496</span> (8.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,258,496\u001b[0m (8.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build model: MobileNetV2 base + lightweight classification head\n",
    "base_model = MobileNetV2(input_shape=IMG_SIZE + (3,), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False  # freeze for initial training\n",
    "\n",
    "inputs = layers.Input(shape=IMG_SIZE + (3,))\n",
    "x = inputs\n",
    "x = preprocess_input(x)  # allow passing raw images to this model if needed\n",
    "x = base_model(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=2, name='top_2_accuracy')])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6759b250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.2936 - loss: 1.7285 - top_2_accuracy: 0.5424\n",
      "Epoch 1: val_loss improved from inf to 1.50546, saving model to test3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 142ms/step - accuracy: 0.2936 - loss: 1.7279 - top_2_accuracy: 0.5425 - val_accuracy: 0.4717 - val_loss: 1.5055 - val_top_2_accuracy: 0.6100 - learning_rate: 0.0010\n",
      "Epoch 2/12\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.3417 - loss: 1.3885 - top_2_accuracy: 0.6092\n",
      "Epoch 2: val_loss improved from 1.50546 to 1.44393, saving model to test3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 145ms/step - accuracy: 0.3418 - loss: 1.3884 - top_2_accuracy: 0.6092 - val_accuracy: 0.3012 - val_loss: 1.4439 - val_top_2_accuracy: 0.7342 - learning_rate: 0.0010\n",
      "Epoch 3/12\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.3627 - loss: 1.3249 - top_2_accuracy: 0.6111\n",
      "Epoch 3: val_loss improved from 1.44393 to 1.29106, saving model to test3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 150ms/step - accuracy: 0.3628 - loss: 1.3249 - top_2_accuracy: 0.6112 - val_accuracy: 0.4923 - val_loss: 1.2911 - val_top_2_accuracy: 0.8127 - learning_rate: 0.0010\n",
      "Epoch 4/12\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.3715 - loss: 1.2898 - top_2_accuracy: 0.6463\n",
      "Epoch 4: val_loss did not improve from 1.29106\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 156ms/step - accuracy: 0.3715 - loss: 1.2898 - top_2_accuracy: 0.6463 - val_accuracy: 0.3533 - val_loss: 1.3612 - val_top_2_accuracy: 0.8456 - learning_rate: 0.0010\n",
      "Epoch 5/12\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.3860 - loss: 1.2679 - top_2_accuracy: 0.6660\n",
      "Epoch 5: val_loss improved from 1.29106 to 1.16049, saving model to test3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 156ms/step - accuracy: 0.3860 - loss: 1.2679 - top_2_accuracy: 0.6660 - val_accuracy: 0.5508 - val_loss: 1.1605 - val_top_2_accuracy: 0.8475 - learning_rate: 0.0010\n",
      "Epoch 6/12\n",
      "Epoch 6/12\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.3819 - loss: 1.2764 - top_2_accuracy: 0.6559\n",
      "Epoch 6: val_loss did not improve from 1.16049\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 170ms/step - accuracy: 0.3820 - loss: 1.2764 - top_2_accuracy: 0.6560 - val_accuracy: 0.4524 - val_loss: 1.3010 - val_top_2_accuracy: 0.7452 - learning_rate: 0.0010\n",
      "Epoch 7/12\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.16049\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 170ms/step - accuracy: 0.3820 - loss: 1.2764 - top_2_accuracy: 0.6560 - val_accuracy: 0.4524 - val_loss: 1.3010 - val_top_2_accuracy: 0.7452 - learning_rate: 0.0010\n",
      "Epoch 7/12\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.3750 - loss: 1.2737 - top_2_accuracy: 0.6627\n",
      "Epoch 7: val_loss improved from 1.16049 to 1.13502, saving model to test3_best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 1.16049 to 1.13502, saving model to test3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 175ms/step - accuracy: 0.3751 - loss: 1.2737 - top_2_accuracy: 0.6627 - val_accuracy: 0.4569 - val_loss: 1.1350 - val_top_2_accuracy: 0.8983 - learning_rate: 0.0010\n",
      "Epoch 8/12\n",
      "Epoch 8/12\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.3895 - loss: 1.2508 - top_2_accuracy: 0.6784\n",
      "Epoch 8: val_loss improved from 1.13502 to 1.09000, saving model to test3_best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 1.13502 to 1.09000, saving model to test3_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 181ms/step - accuracy: 0.3895 - loss: 1.2508 - top_2_accuracy: 0.6784 - val_accuracy: 0.5154 - val_loss: 1.0900 - val_top_2_accuracy: 0.8880 - learning_rate: 0.0010\n",
      "Epoch 9/12\n",
      "Epoch 9/12\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.4168 - loss: 1.2461 - top_2_accuracy: 0.6835\n",
      "Epoch 9: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 175ms/step - accuracy: 0.4168 - loss: 1.2461 - top_2_accuracy: 0.6835 - val_accuracy: 0.5026 - val_loss: 1.2178 - val_top_2_accuracy: 0.9041 - learning_rate: 0.0010\n",
      "Epoch 10/12\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 175ms/step - accuracy: 0.4168 - loss: 1.2461 - top_2_accuracy: 0.6835 - val_accuracy: 0.5026 - val_loss: 1.2178 - val_top_2_accuracy: 0.9041 - learning_rate: 0.0010\n",
      "Epoch 10/12\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.3988 - loss: 1.2589 - top_2_accuracy: 0.6793\n",
      "Epoch 10: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 177ms/step - accuracy: 0.3989 - loss: 1.2589 - top_2_accuracy: 0.6794 - val_accuracy: 0.3713 - val_loss: 1.3617 - val_top_2_accuracy: 0.7207 - learning_rate: 0.0010\n",
      "Epoch 11/12\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 177ms/step - accuracy: 0.3989 - loss: 1.2589 - top_2_accuracy: 0.6794 - val_accuracy: 0.3713 - val_loss: 1.3617 - val_top_2_accuracy: 0.7207 - learning_rate: 0.0010\n",
      "Epoch 11/12\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.4093 - loss: 1.2526 - top_2_accuracy: 0.6868\n",
      "Epoch 11: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 176ms/step - accuracy: 0.4093 - loss: 1.2525 - top_2_accuracy: 0.6868 - val_accuracy: 0.4299 - val_loss: 1.1948 - val_top_2_accuracy: 0.9138 - learning_rate: 0.0010\n",
      "Epoch 12/12\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 176ms/step - accuracy: 0.4093 - loss: 1.2525 - top_2_accuracy: 0.6868 - val_accuracy: 0.4299 - val_loss: 1.1948 - val_top_2_accuracy: 0.9138 - learning_rate: 0.0010\n",
      "Epoch 12/12\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.4154 - loss: 1.2379 - top_2_accuracy: 0.6932\n",
      "Epoch 12: val_loss did not improve from 1.09000\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 175ms/step - accuracy: 0.4154 - loss: 1.2379 - top_2_accuracy: 0.6932 - val_accuracy: 0.3945 - val_loss: 1.2187 - val_top_2_accuracy: 0.9073 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.09000\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 175ms/step - accuracy: 0.4154 - loss: 1.2379 - top_2_accuracy: 0.6932 - val_accuracy: 0.3945 - val_loss: 1.2187 - val_top_2_accuracy: 0.9073 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Initial training finished\n",
      "Initial training finished\n"
     ]
    }
   ],
   "source": [
    "# Training callbacks\n",
    "checkpoint_path = 'test3_best_model.h5'\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, verbose=1),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True, verbose=1),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-7, verbose=1),\n",
    "    tf.keras.callbacks.CSVLogger('test3_training_log.csv')\n",
    "]\n",
    "\n",
    "# Initial training: head only\n",
    "INITIAL_EPOCHS = 12\n",
    "history = model.fit(train_ds, epochs=INITIAL_EPOCHS, validation_data=val_ds, callbacks=callbacks, class_weight=class_weights)\n",
    "\n",
    "print('Initial training finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa88e53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/24\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.4959 - loss: 1.1626 - top_2_accuracy: 0.7977\n",
      "Epoch 13: val_loss did not improve from 1.09000\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 262ms/step - accuracy: 0.4962 - loss: 1.1620 - top_2_accuracy: 0.7979 - val_accuracy: 0.2162 - val_loss: 3.9215 - val_top_2_accuracy: 0.5618 - learning_rate: 1.0000e-05\n",
      "Epoch 14/24\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 262ms/step - accuracy: 0.4962 - loss: 1.1620 - top_2_accuracy: 0.7979 - val_accuracy: 0.2162 - val_loss: 3.9215 - val_top_2_accuracy: 0.5618 - learning_rate: 1.0000e-05\n",
      "Epoch 14/24\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.6788 - loss: 0.7833 - top_2_accuracy: 0.9097\n",
      "Epoch 14: val_loss did not improve from 1.09000\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 284ms/step - accuracy: 0.6789 - loss: 0.7832 - top_2_accuracy: 0.9097 - val_accuracy: 0.2175 - val_loss: 3.4733 - val_top_2_accuracy: 0.4324 - learning_rate: 1.0000e-05\n",
      "Epoch 15/24\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 284ms/step - accuracy: 0.6789 - loss: 0.7832 - top_2_accuracy: 0.9097 - val_accuracy: 0.2175 - val_loss: 3.4733 - val_top_2_accuracy: 0.4324 - learning_rate: 1.0000e-05\n",
      "Epoch 15/24\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 0.7232 - loss: 0.6809 - top_2_accuracy: 0.9252\n",
      "Epoch 15: val_loss did not improve from 1.09000\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 329ms/step - accuracy: 0.7232 - loss: 0.6808 - top_2_accuracy: 0.9252 - val_accuracy: 0.2207 - val_loss: 1.6304 - val_top_2_accuracy: 0.5071 - learning_rate: 1.0000e-05\n",
      "Epoch 16/24\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 329ms/step - accuracy: 0.7232 - loss: 0.6808 - top_2_accuracy: 0.9252 - val_accuracy: 0.2207 - val_loss: 1.6304 - val_top_2_accuracy: 0.5071 - learning_rate: 1.0000e-05\n",
      "Epoch 16/24\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.7481 - loss: 0.6192 - top_2_accuracy: 0.9340\n",
      "Epoch 16: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 356ms/step - accuracy: 0.7481 - loss: 0.6191 - top_2_accuracy: 0.9340 - val_accuracy: 0.2188 - val_loss: 1.8069 - val_top_2_accuracy: 0.4305 - learning_rate: 1.0000e-05\n",
      "Epoch 17/24\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 356ms/step - accuracy: 0.7481 - loss: 0.6191 - top_2_accuracy: 0.9340 - val_accuracy: 0.2188 - val_loss: 1.8069 - val_top_2_accuracy: 0.4305 - learning_rate: 1.0000e-05\n",
      "Epoch 17/24\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.7739 - loss: 0.5709 - top_2_accuracy: 0.9411\n",
      "Epoch 17: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 351ms/step - accuracy: 0.7739 - loss: 0.5709 - top_2_accuracy: 0.9411 - val_accuracy: 0.2169 - val_loss: 2.6122 - val_top_2_accuracy: 0.4350 - learning_rate: 1.0000e-05\n",
      "Epoch 18/24\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 351ms/step - accuracy: 0.7739 - loss: 0.5709 - top_2_accuracy: 0.9411 - val_accuracy: 0.2169 - val_loss: 2.6122 - val_top_2_accuracy: 0.4350 - learning_rate: 1.0000e-05\n",
      "Epoch 18/24\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - accuracy: 0.7788 - loss: 0.5393 - top_2_accuracy: 0.9489\n",
      "Epoch 18: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 323ms/step - accuracy: 0.7789 - loss: 0.5392 - top_2_accuracy: 0.9489 - val_accuracy: 0.2162 - val_loss: 2.4524 - val_top_2_accuracy: 0.4485 - learning_rate: 1.0000e-05\n",
      "Epoch 19/24\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 323ms/step - accuracy: 0.7789 - loss: 0.5392 - top_2_accuracy: 0.9489 - val_accuracy: 0.2162 - val_loss: 2.4524 - val_top_2_accuracy: 0.4485 - learning_rate: 1.0000e-05\n",
      "Epoch 19/24\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.7831 - loss: 0.5263 - top_2_accuracy: 0.9517\n",
      "Epoch 19: val_loss did not improve from 1.09000\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 333ms/step - accuracy: 0.7832 - loss: 0.5262 - top_2_accuracy: 0.9517 - val_accuracy: 0.2239 - val_loss: 1.8408 - val_top_2_accuracy: 0.4196 - learning_rate: 1.0000e-05\n",
      "Epoch 20/24\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.09000\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 333ms/step - accuracy: 0.7832 - loss: 0.5262 - top_2_accuracy: 0.9517 - val_accuracy: 0.2239 - val_loss: 1.8408 - val_top_2_accuracy: 0.4196 - learning_rate: 1.0000e-05\n",
      "Epoch 20/24\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 0.8044 - loss: 0.4739 - top_2_accuracy: 0.9645\n",
      "Epoch 20: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 351ms/step - accuracy: 0.8044 - loss: 0.4739 - top_2_accuracy: 0.9645 - val_accuracy: 0.2407 - val_loss: 1.8244 - val_top_2_accuracy: 0.4286 - learning_rate: 5.0000e-06\n",
      "Epoch 21/24\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 351ms/step - accuracy: 0.8044 - loss: 0.4739 - top_2_accuracy: 0.9645 - val_accuracy: 0.2407 - val_loss: 1.8244 - val_top_2_accuracy: 0.4286 - learning_rate: 5.0000e-06\n",
      "Epoch 21/24\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.8196 - loss: 0.4358 - top_2_accuracy: 0.9685\n",
      "Epoch 21: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 349ms/step - accuracy: 0.8196 - loss: 0.4359 - top_2_accuracy: 0.9685 - val_accuracy: 0.2407 - val_loss: 1.6578 - val_top_2_accuracy: 0.5798 - learning_rate: 5.0000e-06\n",
      "Epoch 22/24\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 349ms/step - accuracy: 0.8196 - loss: 0.4359 - top_2_accuracy: 0.9685 - val_accuracy: 0.2407 - val_loss: 1.6578 - val_top_2_accuracy: 0.5798 - learning_rate: 5.0000e-06\n",
      "Epoch 22/24\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step - accuracy: 0.8225 - loss: 0.4267 - top_2_accuracy: 0.9705\n",
      "Epoch 22: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 349ms/step - accuracy: 0.8225 - loss: 0.4267 - top_2_accuracy: 0.9705 - val_accuracy: 0.3205 - val_loss: 1.7347 - val_top_2_accuracy: 0.5322 - learning_rate: 5.0000e-06\n",
      "Epoch 23/24\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 349ms/step - accuracy: 0.8225 - loss: 0.4267 - top_2_accuracy: 0.9705 - val_accuracy: 0.3205 - val_loss: 1.7347 - val_top_2_accuracy: 0.5322 - learning_rate: 5.0000e-06\n",
      "Epoch 23/24\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.8256 - loss: 0.4149 - top_2_accuracy: 0.9715\n",
      "Epoch 23: val_loss did not improve from 1.09000\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 353ms/step - accuracy: 0.8256 - loss: 0.4149 - top_2_accuracy: 0.9715 - val_accuracy: 0.3713 - val_loss: 1.8025 - val_top_2_accuracy: 0.5438 - learning_rate: 5.0000e-06\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.09000\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 353ms/step - accuracy: 0.8256 - loss: 0.4149 - top_2_accuracy: 0.9715 - val_accuracy: 0.3713 - val_loss: 1.8025 - val_top_2_accuracy: 0.5438 - learning_rate: 5.0000e-06\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Fine-tuning finished\n",
      "Fine-tuning finished\n"
     ]
    }
   ],
   "source": [
    "# Fine-tuning: unfreeze last layers of base model and train with a low LR\n",
    "# Unfreeze from a certain layer to allow some representation learning\n",
    "UNFREEZE_AT = 100  # layer index to start unfreezing (tune as needed)\n",
    "for layer in base_model.layers[UNFREEZE_AT:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=2, name='top_2_accuracy')])\n",
    "\n",
    "FINE_TUNE_EPOCHS = 12\n",
    "total_epochs = INITIAL_EPOCHS + FINE_TUNE_EPOCHS\n",
    "history_fine = model.fit(train_ds, epochs=total_epochs, initial_epoch=INITIAL_EPOCHS, validation_data=val_ds, callbacks=callbacks, class_weight=class_weights)\n",
    "\n",
    "print('Fine-tuning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83f9ce8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on: test\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - accuracy: 0.1359 - loss: 1.7609 - top_2_accuracy: 0.4190\n",
      "Evaluation results: [1.767214298248291, 0.12704917788505554, 0.4330601096153259]\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - accuracy: 0.1359 - loss: 1.7609 - top_2_accuracy: 0.4190\n",
      "Evaluation results: [1.767214298248291, 0.12704917788505554, 0.4330601096153259]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charinduliyanage17/Documents/GitHub/Research_Test/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/charinduliyanage17/Documents/GitHub/Research_Test/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/charinduliyanage17/Documents/GitHub/Research_Test/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Closed_Eyes       0.00      0.00      0.00       361\n",
      "     No_yawn       0.00      0.00      0.00       469\n",
      "   Open_Eyes       0.13      1.00      0.23       186\n",
      "        Yawn       0.00      0.00      0.00       448\n",
      "\n",
      "    accuracy                           0.13      1464\n",
      "   macro avg       0.03      0.25      0.06      1464\n",
      "weighted avg       0.02      0.13      0.03      1464\n",
      "\n",
      "Model saved to test3_final_model\n",
      "Model saved to test3_final_model\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test / validation set and show confusion matrix\n",
    "eval_ds = test_ds if test_ds is not None else val_ds\n",
    "print('Evaluating on:', 'test' if test_ds is not None else 'val')\n",
    "results = model.evaluate(eval_ds)\n",
    "print('Evaluation results:', results)\n",
    "\n",
    "# Predict and compute confusion matrix and classification report\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for images, labels in eval_ds:\n",
    "    preds = model.predict(images)\n",
    "    y_pred.extend(np.argmax(preds, axis=1).tolist())\n",
    "    y_true.extend(np.argmax(labels.numpy(), axis=1).tolist())\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print('Classification report:')\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "# Save final model (already checkpointed)\n",
    "model.save('test3_final_model.h5')\n",
    "print('Model saved to test3_final_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f83a598",
   "metadata": {},
   "source": [
    "## Notes & next steps\n",
    "- You can tune UNFREEZE_AT, batch size, and learning rates based on GPU/memory.\n",
    "- For larger datasets prefer a bigger batch_size and longer training.\n",
    "- Consider using mixed precision if you have a compatible GPU: `tf.keras.mixed_precision.set_global_policy('mixed_float16')`.\n",
    "- Update `requirements.txt` to pin package versions used in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeabc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing improved training pipeline: mixup + label smoothing + extended fine-tuning\n",
      "Improved train pipeline prepared (mixup + stronger augmentation).\n",
      "Compiling model with label smoothing...\n",
      "Starting initial training for 20 epochs...\n",
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.2503 - loss: 1.4940 - top_2_accuracy: 0.5047\n",
      "Epoch 1: val_loss did not improve from 1.09000\n",
      "\n",
      "Epoch 1: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 223ms/step - accuracy: 0.2503 - loss: 1.4938 - top_2_accuracy: 0.5046 - val_accuracy: 0.2928 - val_loss: 1.5156 - val_top_2_accuracy: 0.5090 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 223ms/step - accuracy: 0.2503 - loss: 1.4938 - top_2_accuracy: 0.5046 - val_accuracy: 0.2928 - val_loss: 1.5156 - val_top_2_accuracy: 0.5090 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.2450 - loss: 1.3989 - top_2_accuracy: 0.4936\n",
      "Epoch 2: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 233ms/step - accuracy: 0.2450 - loss: 1.3988 - top_2_accuracy: 0.4936 - val_accuracy: 0.1731 - val_loss: 1.5578 - val_top_2_accuracy: 0.4916 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\n",
      "Epoch 2: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 233ms/step - accuracy: 0.2450 - loss: 1.3988 - top_2_accuracy: 0.4936 - val_accuracy: 0.1731 - val_loss: 1.5578 - val_top_2_accuracy: 0.4916 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.2518 - loss: 1.3959 - top_2_accuracy: 0.4919\n",
      "Epoch 3: val_loss did not improve from 1.09000\n",
      "\n",
      "Epoch 3: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 265ms/step - accuracy: 0.2517 - loss: 1.3959 - top_2_accuracy: 0.4919 - val_accuracy: 0.2239 - val_loss: 1.3863 - val_top_2_accuracy: 0.5129 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 265ms/step - accuracy: 0.2517 - loss: 1.3959 - top_2_accuracy: 0.4919 - val_accuracy: 0.2239 - val_loss: 1.3863 - val_top_2_accuracy: 0.5129 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.2478 - loss: 1.3928 - top_2_accuracy: 0.5059\n",
      "Epoch 4: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 305ms/step - accuracy: 0.2477 - loss: 1.3928 - top_2_accuracy: 0.5059 - val_accuracy: 0.2928 - val_loss: 1.3921 - val_top_2_accuracy: 0.5090 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 305ms/step - accuracy: 0.2477 - loss: 1.3928 - top_2_accuracy: 0.5059 - val_accuracy: 0.2928 - val_loss: 1.3921 - val_top_2_accuracy: 0.5090 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 0.2410 - loss: 1.3938 - top_2_accuracy: 0.5039\n",
      "Epoch 5: val_loss did not improve from 1.09000\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 327ms/step - accuracy: 0.2409 - loss: 1.3938 - top_2_accuracy: 0.5038 - val_accuracy: 0.2928 - val_loss: 1.3860 - val_top_2_accuracy: 0.5090 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 327ms/step - accuracy: 0.2409 - loss: 1.3938 - top_2_accuracy: 0.5038 - val_accuracy: 0.2928 - val_loss: 1.3860 - val_top_2_accuracy: 0.5090 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.2507 - loss: 1.3924 - top_2_accuracy: 0.4950\n",
      "Epoch 6: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 336ms/step - accuracy: 0.2507 - loss: 1.3924 - top_2_accuracy: 0.4950 - val_accuracy: 0.2162 - val_loss: 1.4127 - val_top_2_accuracy: 0.4324 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 336ms/step - accuracy: 0.2507 - loss: 1.3924 - top_2_accuracy: 0.4950 - val_accuracy: 0.2162 - val_loss: 1.4127 - val_top_2_accuracy: 0.4324 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 0.2643 - loss: 1.3926 - top_2_accuracy: 0.5097\n",
      "Epoch 7: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 326ms/step - accuracy: 0.2643 - loss: 1.3926 - top_2_accuracy: 0.5097 - val_accuracy: 0.2162 - val_loss: 1.4503 - val_top_2_accuracy: 0.5090 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 326ms/step - accuracy: 0.2643 - loss: 1.3926 - top_2_accuracy: 0.5097 - val_accuracy: 0.2162 - val_loss: 1.4503 - val_top_2_accuracy: 0.5090 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.2438 - loss: 1.3961 - top_2_accuracy: 0.5002\n",
      "Epoch 8: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 332ms/step - accuracy: 0.2438 - loss: 1.3961 - top_2_accuracy: 0.5002 - val_accuracy: 0.2162 - val_loss: 1.4042 - val_top_2_accuracy: 0.4324 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 332ms/step - accuracy: 0.2438 - loss: 1.3961 - top_2_accuracy: 0.5002 - val_accuracy: 0.2162 - val_loss: 1.4042 - val_top_2_accuracy: 0.4324 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.2523 - loss: 1.3942 - top_2_accuracy: 0.4913\n",
      "Epoch 9: val_loss did not improve from 1.09000\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 335ms/step - accuracy: 0.2523 - loss: 1.3942 - top_2_accuracy: 0.4913 - val_accuracy: 0.2329 - val_loss: 1.3867 - val_top_2_accuracy: 0.5090 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.09000\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 335ms/step - accuracy: 0.2523 - loss: 1.3942 - top_2_accuracy: 0.4913 - val_accuracy: 0.2329 - val_loss: 1.3867 - val_top_2_accuracy: 0.5090 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.2431 - loss: 1.3917 - top_2_accuracy: 0.4942\n",
      "Epoch 10: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 340ms/step - accuracy: 0.2431 - loss: 1.3917 - top_2_accuracy: 0.4942 - val_accuracy: 0.2162 - val_loss: 1.3965 - val_top_2_accuracy: 0.4794 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 340ms/step - accuracy: 0.2431 - loss: 1.3917 - top_2_accuracy: 0.4942 - val_accuracy: 0.2162 - val_loss: 1.3965 - val_top_2_accuracy: 0.4794 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.2452 - loss: 1.3907 - top_2_accuracy: 0.5021\n",
      "Epoch 11: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 347ms/step - accuracy: 0.2452 - loss: 1.3907 - top_2_accuracy: 0.5021 - val_accuracy: 0.2761 - val_loss: 1.3863 - val_top_2_accuracy: 0.5347 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 347ms/step - accuracy: 0.2452 - loss: 1.3907 - top_2_accuracy: 0.5021 - val_accuracy: 0.2761 - val_loss: 1.3863 - val_top_2_accuracy: 0.5347 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - accuracy: 0.2429 - loss: 1.3915 - top_2_accuracy: 0.4977\n",
      "Epoch 12: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 350ms/step - accuracy: 0.2429 - loss: 1.3915 - top_2_accuracy: 0.4977 - val_accuracy: 0.2162 - val_loss: 1.3887 - val_top_2_accuracy: 0.2986 - learning_rate: 5.0000e-04\n",
      "Epoch 13/20\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 350ms/step - accuracy: 0.2429 - loss: 1.3915 - top_2_accuracy: 0.4977 - val_accuracy: 0.2162 - val_loss: 1.3887 - val_top_2_accuracy: 0.2986 - learning_rate: 5.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.2560 - loss: 1.3891 - top_2_accuracy: 0.5064\n",
      "Epoch 13: val_loss did not improve from 1.09000\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 345ms/step - accuracy: 0.2560 - loss: 1.3891 - top_2_accuracy: 0.5064 - val_accuracy: 0.2349 - val_loss: 1.3901 - val_top_2_accuracy: 0.4891 - learning_rate: 5.0000e-04\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.09000\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 345ms/step - accuracy: 0.2560 - loss: 1.3891 - top_2_accuracy: 0.5064 - val_accuracy: 0.2349 - val_loss: 1.3901 - val_top_2_accuracy: 0.4891 - learning_rate: 5.0000e-04\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Initial training done — now expanding fine-tuning\n",
      "Fine-tuning for additional 30 epochs (total epochs = 50)\n",
      "Epoch 21/50\n",
      "Initial training done — now expanding fine-tuning\n",
      "Fine-tuning for additional 30 epochs (total epochs = 50)\n",
      "Epoch 21/50\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step - accuracy: 0.2659 - loss: 1.3910 - top_2_accuracy: 0.5173\n",
      "Epoch 21: val_loss did not improve from 1.09000\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 474ms/step - accuracy: 0.2659 - loss: 1.3910 - top_2_accuracy: 0.5172 - val_accuracy: 0.2928 - val_loss: 1.4510 - val_top_2_accuracy: 0.5090 - learning_rate: 5.0000e-06\n",
      "Epoch 22/50\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 474ms/step - accuracy: 0.2659 - loss: 1.3910 - top_2_accuracy: 0.5172 - val_accuracy: 0.2928 - val_loss: 1.4510 - val_top_2_accuracy: 0.5090 - learning_rate: 5.0000e-06\n",
      "Epoch 22/50\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step - accuracy: 0.2529 - loss: 1.3926 - top_2_accuracy: 0.4958\n",
      "Epoch 22: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 466ms/step - accuracy: 0.2529 - loss: 1.3926 - top_2_accuracy: 0.4958 - val_accuracy: 0.2928 - val_loss: 1.5103 - val_top_2_accuracy: 0.5090 - learning_rate: 5.0000e-06\n",
      "Epoch 23/50\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 466ms/step - accuracy: 0.2529 - loss: 1.3926 - top_2_accuracy: 0.4958 - val_accuracy: 0.2928 - val_loss: 1.5103 - val_top_2_accuracy: 0.5090 - learning_rate: 5.0000e-06\n",
      "Epoch 23/50\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498ms/step - accuracy: 0.2479 - loss: 1.3899 - top_2_accuracy: 0.5150\n",
      "Epoch 23: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 531ms/step - accuracy: 0.2480 - loss: 1.3899 - top_2_accuracy: 0.5150 - val_accuracy: 0.2928 - val_loss: 1.5328 - val_top_2_accuracy: 0.5090 - learning_rate: 5.0000e-06\n",
      "Epoch 24/50\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 531ms/step - accuracy: 0.2480 - loss: 1.3899 - top_2_accuracy: 0.5150 - val_accuracy: 0.2928 - val_loss: 1.5328 - val_top_2_accuracy: 0.5090 - learning_rate: 5.0000e-06\n",
      "Epoch 24/50\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - accuracy: 0.2449 - loss: 1.3897 - top_2_accuracy: 0.5098\n",
      "Epoch 24: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 486ms/step - accuracy: 0.2449 - loss: 1.3897 - top_2_accuracy: 0.5098 - val_accuracy: 0.2928 - val_loss: 1.7759 - val_top_2_accuracy: 0.5090 - learning_rate: 5.0000e-06\n",
      "Epoch 25/50\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 486ms/step - accuracy: 0.2449 - loss: 1.3897 - top_2_accuracy: 0.5098 - val_accuracy: 0.2928 - val_loss: 1.7759 - val_top_2_accuracy: 0.5090 - learning_rate: 5.0000e-06\n",
      "Epoch 25/50\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - accuracy: 0.2537 - loss: 1.3886 - top_2_accuracy: 0.5165\n",
      "Epoch 25: val_loss did not improve from 1.09000\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 486ms/step - accuracy: 0.2537 - loss: 1.3886 - top_2_accuracy: 0.5165 - val_accuracy: 0.2928 - val_loss: 1.7023 - val_top_2_accuracy: 0.5090 - learning_rate: 5.0000e-06\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.09000\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 486ms/step - accuracy: 0.2537 - loss: 1.3886 - top_2_accuracy: 0.5165 - val_accuracy: 0.2928 - val_loss: 1.7023 - val_top_2_accuracy: 0.5090 - learning_rate: 5.0000e-06\n",
      "Epoch 26/50\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - accuracy: 0.2456 - loss: 1.3912 - top_2_accuracy: 0.5005\n",
      "Epoch 26: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 483ms/step - accuracy: 0.2456 - loss: 1.3912 - top_2_accuracy: 0.5005 - val_accuracy: 0.2928 - val_loss: 1.8387 - val_top_2_accuracy: 0.5090 - learning_rate: 2.5000e-06\n",
      "Epoch 27/50\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 483ms/step - accuracy: 0.2456 - loss: 1.3912 - top_2_accuracy: 0.5005 - val_accuracy: 0.2928 - val_loss: 1.8387 - val_top_2_accuracy: 0.5090 - learning_rate: 2.5000e-06\n",
      "Epoch 27/50\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step - accuracy: 0.2528 - loss: 1.3907 - top_2_accuracy: 0.4982\n",
      "Epoch 27: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 497ms/step - accuracy: 0.2528 - loss: 1.3907 - top_2_accuracy: 0.4982 - val_accuracy: 0.2928 - val_loss: 2.0986 - val_top_2_accuracy: 0.5090 - learning_rate: 2.5000e-06\n",
      "Epoch 28/50\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 497ms/step - accuracy: 0.2528 - loss: 1.3907 - top_2_accuracy: 0.4982 - val_accuracy: 0.2928 - val_loss: 2.0986 - val_top_2_accuracy: 0.5090 - learning_rate: 2.5000e-06\n",
      "Epoch 28/50\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505ms/step - accuracy: 0.2548 - loss: 1.3882 - top_2_accuracy: 0.5118\n",
      "Epoch 28: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 541ms/step - accuracy: 0.2548 - loss: 1.3882 - top_2_accuracy: 0.5118 - val_accuracy: 0.2921 - val_loss: 1.9424 - val_top_2_accuracy: 0.5090 - learning_rate: 2.5000e-06\n",
      "Epoch 29/50\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.09000\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 541ms/step - accuracy: 0.2548 - loss: 1.3882 - top_2_accuracy: 0.5118 - val_accuracy: 0.2921 - val_loss: 1.9424 - val_top_2_accuracy: 0.5090 - learning_rate: 2.5000e-06\n",
      "Epoch 29/50\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.2451 - loss: 1.3911 - top_2_accuracy: 0.4981\n",
      "Epoch 29: val_loss did not improve from 1.09000\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m910s\u001b[0m 3s/step - accuracy: 0.2451 - loss: 1.3911 - top_2_accuracy: 0.4981 - val_accuracy: 0.2876 - val_loss: 1.5384 - val_top_2_accuracy: 0.5077 - learning_rate: 2.5000e-06\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.09000\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m910s\u001b[0m 3s/step - accuracy: 0.2451 - loss: 1.3911 - top_2_accuracy: 0.4981 - val_accuracy: 0.2876 - val_loss: 1.5384 - val_top_2_accuracy: 0.5077 - learning_rate: 2.5000e-06\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Fine-tuning finished\n",
      "Running TTA evaluation on validation/test set (simple horizontal flips)\n",
      "Fine-tuning finished\n",
      "Running TTA evaluation on validation/test set (simple horizontal flips)\n",
      "TTA accuracy: 0.3203551912568306\n",
      "TTA accuracy: 0.3203551912568306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 01:14:08.305656: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charinduliyanage17/Documents/GitHub/Research_Test/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/charinduliyanage17/Documents/GitHub/Research_Test/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/charinduliyanage17/Documents/GitHub/Research_Test/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report (TTA):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Closed_Eyes       0.00      0.00      0.00       361\n",
      "     No_yawn       0.32      1.00      0.49       469\n",
      "   Open_Eyes       0.00      0.00      0.00       186\n",
      "        Yawn       0.00      0.00      0.00       448\n",
      "\n",
      "    accuracy                           0.32      1464\n",
      "   macro avg       0.08      0.25      0.12      1464\n",
      "weighted avg       0.10      0.32      0.16      1464\n",
      "\n",
      "Saved model to test3_final_model_v2\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# === Accuracy improvement cell ===\n",
    "# Mixup, label smoothing, stronger augmentation, longer training and expanded fine-tuning\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print('Preparing improved training pipeline: mixup + label smoothing + extended fine-tuning')\n",
    "\n",
    "# 1) Mixup helper (uses numpy for Beta sampling, wrapped for TF pipeline)\n",
    "def _mixup_numpy(images, labels, alpha=0.2):\n",
    "    # images: (batch, H, W, C), labels: (batch, num_classes)\n",
    "    if alpha <= 0:\n",
    "        return images, labels\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = images.shape[0]\n",
    "    index = np.random.permutation(batch_size)\n",
    "    mixed_images = lam * images + (1.0 - lam) * images[index]\n",
    "    mixed_labels = lam * labels + (1.0 - lam) * labels[index]\n",
    "    return mixed_images.astype(np.float32), mixed_labels.astype(np.float32)\n",
    "\n",
    "\n",
    "def mixup_batch(images, labels, alpha=0.2):\n",
    "    mixed_images, mixed_labels = tf.numpy_function(func=_mixup_numpy, inp=[images, labels, alpha], Tout=[tf.float32, tf.float32])\n",
    "    # restore static shape information\n",
    "    mixed_images.set_shape(images.shape)\n",
    "    mixed_labels.set_shape(labels.shape)\n",
    "    return mixed_images, mixed_labels\n",
    "\n",
    "# 2) Stronger on-the-fly augmentation (added brightness/contrast/gaussian-ish noise)\n",
    "data_augmentation_improved = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip('horizontal'),\n",
    "    tf.keras.layers.RandomRotation(0.12),\n",
    "    tf.keras.layers.RandomZoom(0.12),\n",
    "    tf.keras.layers.RandomContrast(0.12),\n",
    "    tf.keras.layers.RandomTranslation(0.05, 0.05),\n",
    "])\n",
    "\n",
    "# Insert the improved augmentation into the pipeline\n",
    "# Note: train_ds is expected to already exist (from earlier cells). We'll create a new pipeline\n",
    "try:\n",
    "    # re-create training pipeline: preprocess (mobilenet), augment, mixup, cache/shuffle/prefetch\n",
    "    def preprocess_fn(images, labels):\n",
    "        images = tf.cast(images, tf.float32)\n",
    "        images = tf.keras.applications.mobilenet_v2.preprocess_input(images)\n",
    "        return images, labels\n",
    "\n",
    "    def augment_fn(images, labels):\n",
    "        images = data_augmentation_improved(images)\n",
    "        return images, labels\n",
    "\n",
    "    # Apply in this order: preprocess -> augment -> mixup -> cache/shuffle/prefetch\n",
    "    train_ds_improved = train_ds.map(preprocess_fn, num_parallel_calls=AUTOTUNE)\n",
    "    train_ds_improved = train_ds_improved.map(augment_fn, num_parallel_calls=AUTOTUNE)\n",
    "    # apply mixup with alpha=0.2\n",
    "    train_ds_improved = train_ds_improved.map(lambda x, y: mixup_batch(x, y, 0.2), num_parallel_calls=AUTOTUNE)\n",
    "    train_ds_improved = train_ds_improved.cache().shuffle(1000, seed=SEED).prefetch(AUTOTUNE)\n",
    "\n",
    "    # validation/test: just preprocess (should already be set up as val_ds)\n",
    "    val_ds_prepped = val_ds  # already preprocessed in previous pipeline\n",
    "\n",
    "    print('Improved train pipeline prepared (mixup + stronger augmentation).')\n",
    "except NameError as e:\n",
    "    print('train_ds or related variables not found in the notebook environment. Run data-loading cells first.')\n",
    "    raise\n",
    "\n",
    "# 3) Label smoothing loss (helps generalization slightly)\n",
    "label_smoothing = 0.07\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(label_smoothing=label_smoothing)\n",
    "\n",
    "# 4) Rebuild/compile model head with the loss; keep base frozen for initial training\n",
    "print('Compiling model with label smoothing...')\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=2, name='top_2_accuracy')])\n",
    "\n",
    "# 5) Increase initial epochs and fine-tune longer\n",
    "INITIAL_EPOCHS = 20\n",
    "FINE_TUNE_EPOCHS = 30\n",
    "\n",
    "# callbacks (reuse existing callbacks list if available, otherwise create)\n",
    "try:\n",
    "    callbacks  # noqa: F821\n",
    "except NameError:\n",
    "    checkpoint_path = 'test3_best_model.h5'\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, verbose=1),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True, verbose=1),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-7, verbose=1),\n",
    "        tf.keras.callbacks.CSVLogger('test3_training_log.csv')\n",
    "    ]\n",
    "\n",
    "print(f'Starting initial training for {INITIAL_EPOCHS} epochs...')\n",
    "history = model.fit(train_ds_improved, epochs=INITIAL_EPOCHS, validation_data=val_ds_prepped, callbacks=callbacks, class_weight=class_weights)\n",
    "\n",
    "print('Initial training done — now expanding fine-tuning')\n",
    "\n",
    "# 6) Fine-tuning: unfreeze more of the base model and train with a low LR and longer schedule\n",
    "UNFREEZE_AT = 50  # unfreeze from this layer index; tune if needed\n",
    "for layer in base_model.layers[UNFREEZE_AT:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# recompile with a lower LR\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-6),\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=2, name='top_2_accuracy')])\n",
    "\n",
    "total_epochs = INITIAL_EPOCHS + FINE_TUNE_EPOCHS\n",
    "print(f'Fine-tuning for additional {FINE_TUNE_EPOCHS} epochs (total epochs = {total_epochs})')\n",
    "history_fine = model.fit(train_ds_improved, epochs=total_epochs, initial_epoch=INITIAL_EPOCHS, validation_data=val_ds_prepped, callbacks=callbacks, class_weight=class_weights)\n",
    "\n",
    "print('Fine-tuning finished')\n",
    "\n",
    "# 7) Optional: simple Test-Time Augmentation (TTA) evaluation to potentially boost final accuracy\n",
    "print('Running TTA evaluation on validation/test set (simple horizontal flips)')\n",
    "eval_ds = test_ds if 'test_ds' in globals() and test_ds is not None else val_ds_prepped\n",
    "\n",
    "def tta_predict(model, dataset, tta_transforms=2):\n",
    "    preds_all = []\n",
    "    for t in range(tta_transforms):\n",
    "        preds_batch = []\n",
    "        for images, labels in dataset:\n",
    "            if t == 1:\n",
    "                # simple horizontal flip TTA\n",
    "                images_t = tf.image.flip_left_right(images)\n",
    "            else:\n",
    "                images_t = images\n",
    "            preds = model.predict(images_t, verbose=0)\n",
    "            preds_batch.append(preds)\n",
    "        preds_all.append(np.vstack(preds_batch))\n",
    "    # average predictions\n",
    "    avg_preds = np.mean(preds_all, axis=0)\n",
    "    return avg_preds\n",
    "\n",
    "avg_preds = tta_predict(model, eval_ds, tta_transforms=2)\n",
    "# collect y_true\n",
    "y_true = []\n",
    "y_pred = []\n",
    "idx = 0\n",
    "for images, labels in eval_ds:\n",
    "    batch_size_cur = images.shape[0]\n",
    "    y_true.extend(np.argmax(labels.numpy(), axis=1).tolist())\n",
    "    y_pred.extend(np.argmax(avg_preds[idx: idx + batch_size_cur], axis=1).tolist())\n",
    "    idx += batch_size_cur\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print('TTA accuracy:', acc)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (TTA)')\n",
    "plt.show()\n",
    "\n",
    "print('\\nClassification report (TTA):')\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "# Save final model and training histories\n",
    "model.save('test3_final_model_v2.h5')\n",
    "print('Saved model to test3_final_model_v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335c74fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
