{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45da4a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 files: ['10min- 1.csv', '10min- 2.csv', '10min- 3.csv', '13min.csv', '18min- 1.csv', '18min- 2.csv']\n",
      "Processing 10min- 1.csv...\n",
      "Processing 10min- 2.csv...\n",
      "Processing 10min- 3.csv...\n",
      "Processing 13min.csv...\n",
      "Processing 18min- 1.csv...\n",
      "Processing 18min- 2.csv...\n",
      "Generated 6623 training samples.\n",
      "Saved to 'training_data.json'. READY FOR AI!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # converts the JSON into a DataFrame.\n",
    "import numpy as np # used internally by pandas & sklearn.\n",
    "import glob\n",
    "import json\n",
    "\n",
    "# CONFIGURATION\n",
    "WINDOW_SIZE = 50   # 50 readings = approx 1 second (at 20ms rate)\n",
    "STEP_SIZE = 10     # Overlap windows to get more data\n",
    "INPUT_FILES = \"*.csv\" # Finds all your CSVs\n",
    "\n",
    "def calculate_magnitude(row): # In the dataset, each row represents one timestamped sample from your smartphone sensor readings.\n",
    "\n",
    "    return np.sqrt(row['acc_x']**2 + row['acc_y']**2 + row['acc_z']**2) # Combine X, Y, Z into one \"Force\" number (ignoring rotation)\n",
    "    # row['acc_x']-accesses the X-axis acceleration value from the sensor and likewise\n",
    "    # np.sqrt()-gives a single value representing the TOTAL force acting on the device.\n",
    "\n",
    "def process_files(): # the begining of the windowing + feature extraction logic \n",
    "    all_files = glob.glob(INPUT_FILES) # Finds CSV files (returns all filenames matching \"*.csv\")\n",
    "    print(f\"Found {len(all_files)} files: {all_files}\")\n",
    "\n",
    "    processed_samples = [] # Each training sample (one window of data) will be stored as a dictionary inside this list.\n",
    "    \n",
    "    for filename in all_files:\n",
    "        print(f\"Processing {filename}...\") # Good for progress tracking.\n",
    "        try:\n",
    "            df = pd.read_csv(filename) # Reads the CSV file into a pandas DataFrame.\n",
    "            \n",
    "            # 1. Feature Engineering section- Now the core preprocessing starts.\n",
    "            # Calculate Total Force (Magnitude) and For every row, apply the previously defined calculate_magnitude() function\n",
    "            df['mag'] = df.apply(calculate_magnitude, axis=1) # axis=1 means \"apply function on each row\"\n",
    "            \n",
    "            # Calculate Jerk (Change in Force)--> calculates difference between each two consecutive magnitude values.\n",
    "            df['jerk'] = df['mag'].diff().fillna(0) # fillna(0) replaces the first NaN with 0.\n",
    "            \n",
    "            # Fill missing GPS speeds with 0 to avoid errors during mean() calculations\n",
    "            df['gps_speed'] = df['gps_speed'].fillna(0)\n",
    "\n",
    "            # 2. Sliding Window Logic\n",
    "            \n",
    "            for i in range(0, len(df) - WINDOW_SIZE, STEP_SIZE): # creates overlapping windows of sensor data. WINDOW_SIZE= training sample, STEP_SIZE= no of forward rows\n",
    "                window = df.iloc[i : i + WINDOW_SIZE] # Extract rows ex:  from index i to i+50\n",
    "                \n",
    "                # The label for this window is the most common label in these 50 rows\n",
    "                label = window['label'].mode()[0] # Mode gives the dominant driving state.\n",
    "                \n",
    "                # Feature Extraction Block- Extract Features from this 1-second chunk\n",
    "                features = {\n",
    "                    \"label\": label,\n",
    "                    \"avg_speed\": float(window['gps_speed'].mean()), # average of the speed values in the window (typical speed)\n",
    "                    \"max_force\": float(window['mag'].max()), # Highest acceleration magnitude in the window to capture strong events (braking, sudden turns)\n",
    "                    \"std_force\": float(window['mag'].std()), # How much it vibrated--> Measures how much shaking or variation is happening.\n",
    "                    \"min_force\": float(window['mag'].min()), # Lowest magnitude to detect moments when car is steady or stopped.\n",
    "                    \"avg_jerk\": float(window['jerk'].abs().mean()) # Represents smooth vs sudden movement transitions.\n",
    "                }\n",
    "                \n",
    "                processed_samples.append(features) # Adds the computed feature dictionary to the list. ex: {\"label\":\"Cruising\", \"avg_speed\":3.2, ...}\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {filename} due to error: {e}\")\n",
    "\n",
    "    # 3. Save to JSON--> the input dataset used for model training.\n",
    "    print(f\"Generated {len(processed_samples)} training samples.\")\n",
    "    with open('training_data.json', 'w') as f: # Opens a file named training_data.json in write mode.\n",
    "        json.dump(processed_samples, f) # Writes the list as formatted JSON.\n",
    "    print(\"Saved to 'training_data.json'. READY FOR AI!\")\n",
    "\n",
    "if __name__ == \"__main__\": # fill here\n",
    "    process_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20c56802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (2.3.3)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.7-cp314-cp314-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (1.7.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (from seaborn) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (from pandas) (2025.2)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.3-cp314-cp314-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.61.0-cp314-cp314-win_amd64.whl.metadata (115 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp314-cp314-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (from matplotlib) (12.0.0)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading matplotlib-3.10.7-cp314-cp314-win_amd64.whl (8.3 MB)\n",
      "   ---------------------------------------- 0.0/8.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/8.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/8.3 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/8.3 MB 797.0 kB/s eta 0:00:10\n",
      "   --- ------------------------------------ 0.8/8.3 MB 925.7 kB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 1.0/8.3 MB 1.0 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.3/8.3 MB 1.1 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 1.6/8.3 MB 1.1 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 1.8/8.3 MB 1.2 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 2.1/8.3 MB 1.2 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 2.4/8.3 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 2.6/8.3 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 2.9/8.3 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 2.9/8.3 MB 1.1 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 3.1/8.3 MB 1.1 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 3.4/8.3 MB 1.1 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 3.4/8.3 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 3.9/8.3 MB 1.1 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 4.2/8.3 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 4.7/8.3 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 5.2/8.3 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 5.5/8.3 MB 1.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 5.8/8.3 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 6.0/8.3 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 6.6/8.3 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 7.1/8.3 MB 1.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.3/8.3 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.9/8.3 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.3/8.3 MB 1.4 MB/s  0:00:05\n",
      "Downloading contourpy-1.3.3-cp314-cp314-win_amd64.whl (232 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.61.0-cp314-cp314-win_amd64.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.3 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.8/2.3 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.3/2.3 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.8/2.3 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 2.2 MB/s  0:00:01\n",
      "Downloading kiwisolver-1.4.9-cp314-cp314-win_amd64.whl (75 kB)\n",
      "Downloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib, seaborn\n",
      "\n",
      "   ---------------------------------------- 0/7 [pyparsing]\n",
      "   ----- ---------------------------------- 1/7 [kiwisolver]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ---------------------- ----------------- 4/7 [contourpy]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [seaborn]\n",
      "   ---------------------------------- ----- 6/7 [seaborn]\n",
      "   ---------------------------------- ----- 6/7 [seaborn]\n",
      "   ---------------------------------------- 7/7 [seaborn]\n",
      "\n",
      "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.61.0 kiwisolver-1.4.9 matplotlib-3.10.7 pyparsing-3.2.5 seaborn-0.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install seaborn pandas matplotlib scikit-learn joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea51797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training_data.json...\n",
      "\n",
      "Total Samples: 6623\n",
      "Class Distribution (Before Balancing):\n",
      "label\n",
      "Cruising      4772\n",
      "Braking       1152\n",
      "Lane Left      419\n",
      "Lane Right     251\n",
      "Pullover        29\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Training Random Forest Model...\n",
      "\n",
      "--- MODEL REPORT CARD ---\n",
      "Overall Accuracy: 88.00%\n",
      "\n",
      "Detailed Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Braking       0.85      0.78      0.81       219\n",
      "    Cruising       0.89      0.98      0.93       952\n",
      "   Lane Left       0.86      0.56      0.68        91\n",
      "  Lane Right       0.92      0.19      0.31        59\n",
      "    Pullover       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.88      1325\n",
      "   macro avg       0.90      0.55      0.63      1325\n",
      "weighted avg       0.88      0.88      0.86      1325\n",
      "\n",
      "\n",
      "Confusion Matrix (Rows=Actual, Cols=Predicted):\n",
      "[[171  43   4   1   0]\n",
      " [ 17 932   3   0   0]\n",
      " [ 12  28  51   0   0]\n",
      " [  1  47   0  11   0]\n",
      " [  0   2   1   0   1]]\n",
      "\n",
      "--- SENSOR IMPORTANCE ---\n",
      "1. avg_speed: 0.3311\n",
      "2. min_force: 0.1946\n",
      "3. avg_jerk: 0.1879\n",
      "4. max_force: 0.1462\n",
      "5. std_force: 0.1402\n",
      "\n",
      "[SUCCESS] Model saved as 'ambulance_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # loads JSON, CSV, and manage data tables as well.\n",
    "import json\n",
    "import seaborn as sns # Makes statistical plots\n",
    "import matplotlib.pyplot as plt # creates graphs/plots\n",
    "from sklearn.model_selection import train_test_split # Splits dataset into training (80%) and testing (20%). (sklearn.model_selection- ML library used for training RandomForest)\n",
    "from sklearn.ensemble import RandomForestClassifier # Loads the RandomForest algorithm.\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score # Provides evaluation metrics.\n",
    "import joblib # save and load trained ML (.pkl file) models to disk\n",
    "# ML Model Training Section\n",
    "def train_ambulance_ai(): # performs the entire training procedure.\n",
    "    # 1. Load the processed data\n",
    "    print(\"Loading training_data.json...\")\n",
    "    try:\n",
    "        with open('training_data.json', 'r') as f: # Opens the JSON file created earlier.\n",
    "            data = json.load(f) # Loads all training samples into the variable (data).\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: 'training_data.json' not found. Run process_data.py first!\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(data) # converts my JSON training samples into a structured Excel-like table (ML friendly)\n",
    "\n",
    "    # 2. Sanity Check\n",
    "    print(f\"\\nTotal Samples: {len(df)}\") # Checks dataset size.\n",
    "    print(\"Class Distribution (Before Balancing):\")\n",
    "    print(df['label'].value_counts()) # Shows how many samples each class (label) has.\n",
    "\n",
    "    # 3. Prepare Inputs (X) and Outputs (y)\n",
    "    X = df.drop(columns=['label']) # numeric feature columns (avg_speed, max_force..) only.\n",
    "    y = df['label'] # correct class for each window (row).\n",
    "\n",
    "    # 4. Split into Training (80%) and Testing (20%)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # ensures reproducible results by fixing the random seed. Start your random number generator from this exact position (42).\n",
    "\n",
    "    # 5. Train the Random Forest\n",
    "    # 'class_weight=\"balanced\"' is CRITICAL here. \n",
    "    # It tells the AI: \"Pay 10x more attention to 'Braking' than 'Cruising' because it's rare.\"\n",
    "    print(\"\\nTraining Random Forest Model...\")\n",
    "    model = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42) # Use 100 decision trees inside the forest, helps the model correctly identify and doesn't ignore rare classes behaviors like braking, turning, or pullover.\n",
    "    model.fit(X_train, y_train) # Train the model; The model learns patterns in the training data.\n",
    "\n",
    "    # 6. Evaluate\n",
    "    print(\"\\n--- MODEL REPORT CARD ---\")\n",
    "    y_pred = model.predict(X_test) # Predict test labels; Run the trained model on the test dataset & Compare predicted labels with true labels.\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred) # Evaluate Model Performance\n",
    "    print(f\"Overall Accuracy: {accuracy:.2%}\")\n",
    "    \n",
    "    print(\"\\nDetailed Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # 7. Confusion Matrix (Where did it get confused?)\n",
    "    print(\"\\nConfusion Matrix (Rows=Actual, Cols=Predicted):\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "\n",
    "    # 8. Feature Importance (What sensors mattered?)\n",
    "    print(\"\\n--- SENSOR IMPORTANCE ---\")\n",
    "    importances = model.feature_importances_\n",
    "    features = X.columns\n",
    "    # Sort them\n",
    "    indices = importances.argsort()[::-1]\n",
    "    for i in range(len(features)):\n",
    "        print(f\"{i+1}. {features[indices[i]]}: {importances[indices[i]]:.4f}\")\n",
    "\n",
    "    # 9. Save the Model\n",
    "    joblib.dump(model, 'ambulance_model.pkl')\n",
    "    print(\"\\n[SUCCESS] Model saved as 'ambulance_model.pkl'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_ambulance_ai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e38560f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (0.13.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (2.3.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (3.10.7)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (1.7.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (from seaborn) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (from matplotlib) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install seaborn pandas matplotlib scikit-learn joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb568f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting m2cgen\n",
      "  Downloading m2cgen-0.10.0-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\janak\\appdata\\roaming\\python\\python314\\site-packages (from m2cgen) (2.3.5)\n",
      "Downloading m2cgen-0.10.0-py3-none-any.whl (92 kB)\n",
      "Installing collected packages: m2cgen\n",
      "Successfully installed m2cgen-0.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install m2cgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d747fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ambulance_model.pkl...\n",
      "Converting to JavaScript...\n",
      "Success! Model saved as ambulance_model.js\n",
      "Action Required: Move 'ambulance_model.js' into your 'app' folder manually.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import m2cgen as m2c\n",
    "import json\n",
    "import os\n",
    "\n",
    "# 1. Load your trained AI model\n",
    "print(\"Loading ambulance_model.pkl...\")\n",
    "try:\n",
    "    model = joblib.load('ambulance_model.pkl')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'ambulance_model.pkl' not found. Make sure you ran train_model.py!\")\n",
    "    exit()\n",
    "\n",
    "# 2. Convert it to JavaScript code\n",
    "print(\"Converting to JavaScript...\")\n",
    "# This turns the random forest trees into a huge \"if/else\" function\n",
    "js_code = m2c.export_to_javascript(model)\n",
    "\n",
    "# 3. Add the \"export\" keyword so React Native can use it\n",
    "final_js = \"export default \" + js_code\n",
    "\n",
    "# 4. Save it to the CURRENT directory first (safest for Jupyter)\n",
    "output_filename = 'ambulance_model.js' \n",
    "\n",
    "with open(output_filename, 'w') as f:\n",
    "    f.write(final_js)\n",
    "\n",
    "print(f\"Success! Model saved as {output_filename}\")\n",
    "print(f\"Action Required: Move '{output_filename}' into your 'app' folder manually.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fda444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
